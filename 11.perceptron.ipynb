{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fda280fa-950d-40a7-9fe2-ed0fdf9a35ec",
   "metadata": {
    "id": "fda280fa-950d-40a7-9fe2-ed0fdf9a35ec"
   },
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1aa603-94b4-4496-8dae-c66508bdf420",
   "metadata": {
    "id": "6e1aa603-94b4-4496-8dae-c66508bdf420"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bae2d8-561e-45d6-b953-e5a7ab569cb6",
   "metadata": {
    "id": "d2bae2d8-561e-45d6-b953-e5a7ab569cb6"
   },
   "source": [
    "## Uczenie perceptronu\n",
    "\n",
    "Uczenie perceptronu to iteracyjny algorytm dopasowywania wag, majƒÖcy na celu poprawnƒÖ klasyfikacjƒô przyk≈Çad√≥w treningowych. Aktualizacja wag nastƒôpuje tylko wtedy, gdy model pope≈Çni b≈ÇƒÖd.\n",
    "\n",
    "### Parametry:\n",
    "\n",
    "- **Learning rate**: $h > 0$ ‚Äì wsp√≥≈Çczynnik uczenia, decydujƒÖcy o wielko≈õci aktualizacji wag.\n",
    "- **Epochs**: $N \\in \\mathbb{N}$ ‚Äì liczba pe≈Çnych przej≈õƒá przez zbi√≥r treningowy.\n",
    "- **Wektor wag poczƒÖtkowych**: $\\mathbf{v} \\in \\mathbb{R}^d$ ‚Äì inicjalizowany losowo lub jako wektor zerowy.\n",
    "\n",
    "---\n",
    "\n",
    "### Algorytm uczenia:\n",
    "\n",
    "Dla ka≈ºdego przyk≈Çadu treningowego $(\\mathbf{x}_i, y_i)$, gdzie:\n",
    "- $\\mathbf{x}_i \\in \\mathbb{R}^d$ ‚Äì wektor cech,\n",
    "- $y_i \\in \\{0, 1\\}$ ‚Äì etykieta klasowa,\n",
    "\n",
    "wykonujemy:\n",
    "\n",
    "1. **Obliczenie wej≈õcia modelu**:\n",
    "\n",
    "$$\n",
    "z_i = \\mathbf{v}^\\top \\mathbf{x}_i\n",
    "$$\n",
    "\n",
    "czyli iloczynu skalarnego wag i wektora cech.\n",
    "\n",
    "2. **Predykcja modelu**:\n",
    "\n",
    "$$\n",
    "p_i = H(z_i)\n",
    "$$\n",
    "\n",
    "gdzie $H(z)$ to funkcja aktywacji Heaviside‚Äôa:\n",
    "\n",
    "$$\n",
    "H(z) =\n",
    "\\begin{cases}\n",
    "1 & \\text{je≈õli } z \\geq 0 \\\\\\\\\n",
    "0 & \\text{w przeciwnym razie}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "3. **Sprawdzenie poprawno≈õci klasyfikacji**:\n",
    "   - Je≈õli $p_i = y_i$, to przyk≈Çad zosta≈Ç poprawnie sklasyfikowany ‚Äì **brak zmian**.\n",
    "   - Je≈õli $p_i \\ne y_i$, to dokonujemy aktualizacji wag:\n",
    "\n",
    "$$\n",
    "\\mathbf{v} \\leftarrow \\mathbf{v} + h \\cdot (y_i - p_i) \\cdot \\mathbf{x}_i\n",
    "$$\n",
    "\n",
    "**Intuicja aktualizacji:**\n",
    "- Gdy $y_i = 1$, $p_i = 0$ ‚Üí dodajemy $h \\cdot \\mathbf{x}_i$\n",
    "- Gdy $y_i = 0$, $p_i = 1$ ‚Üí odejmujemy $h \\cdot \\mathbf{x}_i$\n",
    "\n",
    "**Uwaga:**  \n",
    "Korekta wag zmienia warto≈õƒá iloczynu skalarnego proporcjonalnie do normy przyk≈Çadu:\n",
    "\n",
    "$$\n",
    "(\\mathbf{v} \\pm h \\cdot \\mathbf{x}_i)^\\top \\mathbf{x}_i = \\mathbf{v}^\\top \\mathbf{x}_i \\pm h \\cdot \\|\\mathbf{x}_i\\|^2\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ipb4kw52PO5F",
   "metadata": {
    "id": "ipb4kw52PO5F"
   },
   "outputs": [],
   "source": [
    "\"\"\"Funkcja Heaviside'a.\"\"\"\n",
    "def heaviside(x):\n",
    "    return np.where(x >= 0, 1, 0)\n",
    "\n",
    "\"\"\"Perceptron\"\"\"\n",
    "class Perceptron():\n",
    "    def __init__(self, learning_rate=0.1, epochs=20):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "\n",
    "    def predict(self, X):\n",
    "        return heaviside(np.dot(X, self.weights))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.random.randn(n_features)\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            for idx, x_i in enumerate(X):\n",
    "                y_predicted = heaviside(np.dot(x_i, self.weights))\n",
    "\n",
    "                update = self.learning_rate * (y[idx] - y_predicted)\n",
    "                self.weights += update * x_i\n",
    "\n",
    "    def accuracy(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return np.mean(y_pred == y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fs7ezrNsSZrI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fs7ezrNsSZrI",
    "outputId": "afe76a08-7659-4bbe-f0be-cf80e4c813a5"
   },
   "outputs": [],
   "source": [
    "def wizualizacja(X, y, perceptron):\n",
    "    # Trenowanie perceptronu\n",
    "    perceptron.fit(X, y)\n",
    "    acc = perceptron.accuracy(X, y)\n",
    "\n",
    "    # Wizualizacja wynik√≥w z kolejnymi barierami decyzyjnymi\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "\n",
    "    # Ostateczna bariera decyzyjna\n",
    "    Z = perceptron.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.Paired)\n",
    "\n",
    "    # Punkty danych\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', marker='o')\n",
    "    plt.axhline(0, color='black', linewidth=1, linestyle='-')\n",
    "    plt.axvline(0, color='black', linewidth=1, linestyle='-')\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "    plt.title(f'Klasyfikacja perceptronem\\nAccuracy: {acc:.2f}')\n",
    "    plt.show()\n",
    "\n",
    "perceptron_no_bias = Perceptron(learning_rate=0.1, epochs=100)\n",
    "\n",
    "# Generowanie prostych danych\n",
    "e=0.2\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(500, 2)\n",
    "y = np.array([1 if x[0] + x[1]> np.random.normal(loc=0, scale=e) else 0 for x in X])\n",
    "wizualizacja(X,y, perceptron_no_bias)\n",
    "\n",
    "\n",
    "# sytuacja gdy nie ma separowalno≈õci przez liniƒô przechodzƒÖcƒÖ przez zero\n",
    "y = np.array([1 if x[0] + x[1]+1> np.random.normal(loc=0, scale=e) else 0 for x in X])\n",
    "wizualizacja(X,y, perceptron_no_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9r8UjjPmgbue",
   "metadata": {
    "id": "9r8UjjPmgbue"
   },
   "source": [
    "## Rozszerzanie przestrzeni danych by umo≈ºliwiƒá barierƒô postaci\n",
    "$$\n",
    "v^Tx+b \\leq 0\n",
    "$$\n",
    "\n",
    "Rozszerzamy dane z $x$ do $(x,1)$, i na takich rozszerzonych stosujemy model.\n",
    "W praktyce wagi modelu majƒÖ dodatkowƒÖ wsp√≥≈ÇrzƒôdnƒÖ, nazywamy jƒÖ bias.\n",
    "\n",
    "Wtedy pojawia siƒô update zar√≥wno dla $v$ jak i $b$:\n",
    "$$\n",
    "update=h\\cdot (y_i -predicted(x_i))\n",
    "$$\n",
    "i\n",
    "$$\n",
    "weights=weights+h \\cdot update \\cdot x_i, \\, bias=bias+h\\cdot update.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3oV1QICa2Axd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "id": "3oV1QICa2Axd",
    "outputId": "3715e7f5-2e63-4bdf-ee6a-d6ebd10b1925"
   },
   "outputs": [],
   "source": [
    "class PerceptronBias():\n",
    "    def __init__(self, learning_rate=0.1, epochs=20):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def predict(self, X):\n",
    "        return heaviside(np.dot(X, self.weights) + self.bias)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.random.randn(n_features)\n",
    "        self.bias = np.random.rand()\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            for idx, x_i in enumerate(X):\n",
    "                y_predicted = heaviside(np.dot(x_i, self.weights) + self.bias)\n",
    "\n",
    "                update = self.learning_rate * (y[idx] - y_predicted)\n",
    "                self.weights += update * x_i\n",
    "                self.bias += update * 1\n",
    "\n",
    "    def accuracy(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return np.mean(y_pred == y)\n",
    "\n",
    "perceptron_bias = PerceptronBias(learning_rate=0.1, epochs=100)\n",
    "\n",
    "# Generowanie prostych danych\n",
    "e=0.2\n",
    "np.random.seed(0)\n",
    "\n",
    "X = np.random.randn(500, 2)\n",
    "y = np.array([1 if x[0] + x[1] +1> np.random.normal(loc=0, scale=e) else 0 for x in X])\n",
    "wizualizacja(X,y, perceptron_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7106ba0-68c3-45ef-b54b-e7fa38ff5f10",
   "metadata": {
    "id": "d7106ba0-68c3-45ef-b54b-e7fa38ff5f10"
   },
   "source": [
    "M√≥wimy, ≈ºe zbiory $X_0,X_1 \\subset \\mathbb{R}^n$ sƒÖ separowalne liniowo, je≈ºeli istnieje $v \\in \\mathbb{R}^n$ i skalar $b$ taki, ≈ºe\n",
    "$$\n",
    "v^TX_0+b <0, \\, v^T X_1+b > 0\n",
    "$$\n",
    "Inaczej m√≥wiƒÖc dla ka≈ºdego $x_i$ mamy\n",
    "$$\n",
    "H(v^T x_i+b)=y_i.\n",
    "$$\n",
    "\n",
    "Przyk≈Çad zbioru nie separwoalnego liniowo (rozdzielamy O od X):\n",
    "$$\n",
    "\\begin{array}{cc}\n",
    "OX \\\\\n",
    "XO\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "*Twierdzenie* Je≈ºeli zbiory sƒÖ separowalne liniowo, to algorytm uczenia perceptronu jest zbie≈ºny do prawid≈Çowego rozwiƒÖzania kt√≥re rozdziela klasy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "az6vR6azVabh",
   "metadata": {
    "id": "az6vR6azVabh"
   },
   "source": [
    "# A co je≈õli nie da siƒô rozdzieliƒá za pomocƒÖ liniowego modelu?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QcdMs5XrVogW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "QcdMs5XrVogW",
    "outputId": "49c212fa-5cdc-4065-ec82-de46e9ccefff"
   },
   "outputs": [],
   "source": [
    "perceptron = PerceptronBias(learning_rate=0.1, epochs=100)\n",
    "\n",
    "# a co je≈ºeli ko≈Ço?\n",
    "y = np.array([1 if x[0]**2 + x[1]**2 > 1+np.random.normal(loc=0, scale=e) else 0 for x in X])\n",
    "wizualizacja(X,y, perceptron)\n",
    "\n",
    "# moons\n",
    "from sklearn.datasets import make_moons\n",
    "X, y = make_moons(n_samples=300, noise=0.2, random_state=42)\n",
    "wizualizacja(X,y, perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceR79KC8WdyQ",
   "metadata": {
    "id": "ceR79KC8WdyQ"
   },
   "source": [
    "# Zanurzanie w przestrze≈Ñ wysoko wymiarowƒÖ\n",
    "Rozszerzamy przestrze≈Ñ z wej≈õciowej przestrzeni o wiƒôcej cech. Losowo wybrane - wybieramy losowƒÖ macierz o du≈ºym wymiarze i losowy bias, i obk≈Çadamy jakƒÖ≈õ nieliniowo≈õciƒÖ, na przyk≈Çad funkcjƒÖ $relu(x)=\\max(0,x)$ albo $\\tanh(x)$:\n",
    "\n",
    "$$\n",
    "x \\to ReLU(Wx+b)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xWqE1EcsXR5B",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 619
    },
    "id": "xWqE1EcsXR5B",
    "outputId": "de8de312-728e-4bd9-b364-e07b44a4fb36"
   },
   "outputs": [],
   "source": [
    "# F to zanurzenie w wiekszƒÖ przestrze≈Ñ -- reprezentacja\n",
    "\n",
    "\"\"\"Perceptron z reprezentacjƒÖ i augmentacjƒÖ\"\"\"\n",
    "class PerceptronRep:\n",
    "    def __init__(self, learning_rate=0.1, epochs=400):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "        self.bias=None\n",
    "\n",
    "    def predict(self, x, F):\n",
    "        return heaviside(np.dot(F(x), self.weights) + self.bias)\n",
    "\n",
    "    def fit(self, X, y, F):\n",
    "        n_features = len(F(X[0]))\n",
    "        self.weights = np.random.randn(n_features)\n",
    "        self.bias = np.random.rand()\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            for idx, x_i in enumerate(X):\n",
    "                noise=np.random.randn(len(x_i))\n",
    "                y_predicted = heaviside(np.dot(F(x_i), self.weights) + self.bias)\n",
    "\n",
    "                update = self.learning_rate * (y[idx] - y_predicted)\n",
    "                self.weights += update * F(x_i)\n",
    "                self.bias += update\n",
    "\n",
    "    def accuracy(self, X, y, F):\n",
    "        s=0\n",
    "        S=0\n",
    "        for idx, x_i in enumerate(X):\n",
    "          s+=(heaviside(np.dot(F(x_i), self.weights) + self.bias) == y[idx])\n",
    "          S+=1\n",
    "        return s/S\n",
    "\n",
    "\n",
    "def wizualizacjaRep(X_train,y_train,X_test,y_test, F):\n",
    "  # Trenowanie perceptronu\n",
    "  perceptron = PerceptronRep(learning_rate=1, epochs=100)\n",
    "  perceptron.fit(X_train, y_train, F)\n",
    "  acc_train = perceptron.accuracy(X_train, y_train, F)\n",
    "  acc_test = perceptron.accuracy(X_test, y_test, F)\n",
    "\n",
    "  # Wizualizacja wynik√≥w z kolejnymi barierami decyzyjnymi\n",
    "  x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "  y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "  xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))\n",
    "\n",
    "  plt.figure(figsize=(6, 6))\n",
    "\n",
    "  # Ostateczna bariera decyzyjna\n",
    "  Z = perceptron.predict(np.c_[xx.ravel(), yy.ravel()],F)\n",
    "  Z = Z.reshape(xx.shape)\n",
    "  plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.Paired)\n",
    "\n",
    "  # Punkty danych\n",
    "  plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, edgecolors='k', marker='x',alpha=0.7)\n",
    "  plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, edgecolors='k', marker='o')\n",
    "  plt.axhline(0, color='black', linewidth=1, linestyle='-')\n",
    "  plt.axvline(0, color='black', linewidth=1, linestyle='-')\n",
    "  plt.grid(True, which='both', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "  plt.title(f'Klasyfikacja perceptronem \\nAccuracy train: {acc_train:.2f} test:{acc_test:.2f}')\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Zanurzanie w przestrzeni wielowymiarowej\n",
    "liniowe ob≈Ço≈ºone nieliniowo≈õciami\n",
    "\"\"\"\n",
    "dim=50\n",
    "W = np.random.randn(2, dim)  # Macierz zanurzenia\n",
    "b=np.random.randn(dim) # bias\n",
    "\n",
    "# nieliniowo≈õƒá\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# kluczowa funkcja zanurzajƒÖca w wiƒôkszƒÖ przestrze≈Ñ\n",
    "def F(X):\n",
    "  return relu(b+np.dot(X,W))\n",
    "\n",
    "# Tworzenie zbioru danych Moon\n",
    "np.random.seed(42)\n",
    "\n",
    "N=100\n",
    "N_train=N//2\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=N, noise=0.2, random_state=42)\n",
    "\n",
    "X_train=X[:N_train]\n",
    "X_test=X[N_train:]\n",
    "y_train=y[:N_train]\n",
    "y_test=y[N_train:]\n",
    "\n",
    "np.random.seed(None)\n",
    "\n",
    "wizualizacjaRep(X_train,y_train,X_test,y_test,F)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WtraWJFlJrm7",
   "metadata": {
    "id": "WtraWJFlJrm7"
   },
   "source": [
    "# üß† Zadanie ‚Äì Rak Piersi (Breast Cancer Classification)\n",
    "\n",
    "Twoim zadaniem jest klasyfikacja danych z zestawu **Breast Cancer** na podstawie dw√≥ch cech:\n",
    "\n",
    "- `mean radius`\n",
    "- `mean texture`\n",
    "\n",
    "RozwiƒÖzanie wykonamy na dwa sposoby:\n",
    "\n",
    "1. Implementacja w≈Çasnego perceptronu  \n",
    "2. U≈ºycie gotowego modelu perceptronu z `sklearn.linear_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YE1VTGp_NHAj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "YE1VTGp_NHAj",
    "outputId": "9daf8396-9338-490a-e94e-2d9e3d7b526b"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Wczytanie danych\n",
    "data = load_breast_cancer()\n",
    "X = data.data[:, [0, 1]]  # tylko dwie cechy (mean radius, mean texture)\n",
    "\n",
    "y = data.target\n",
    "\n",
    "# Zamiana etykiet na -1 i 1\n",
    "y = np.where(y == 0, -1, 1)\n",
    "\n",
    "X_test=X[400:];\n",
    "y_test=y[400:]\n",
    "X=X[:400]\n",
    "y=y[:400]\n",
    "\n",
    "# Wizualizacja\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='bwr', edgecolor='k')\n",
    "plt.xlabel(data.feature_names[0])\n",
    "plt.ylabel(data.feature_names[1])\n",
    "plt.title(\"Dane wej≈õciowe: Breast Cancer\")\n",
    "plt.show()\n",
    "\n",
    "# Wizualizacja granicy decyzyjnej\n",
    "def plot_decision_boundary(X, y, model):\n",
    "    # Zakres danych\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "\n",
    "    # Siatka punkt√≥w\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "                         np.arange(y_min, y_max, 0.02))\n",
    "\n",
    "    # Predykcja dla ka≈ºdego punktu siatki\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # Wykres\n",
    "    plt.contourf(xx, yy, Z, alpha=0.4, cmap='bwr')\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap='bwr', edgecolor='k')\n",
    "    plt.xlabel(data.feature_names[0])\n",
    "    plt.ylabel(data.feature_names[1])\n",
    "    plt.title(\"Perceptron - granica decyzyjna\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5rVMbn0jSsw-",
   "metadata": {
    "id": "5rVMbn0jSsw-"
   },
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, learning_rate=0.01, n_iters=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_output = np.dot(X, self.weights) + self.bias\n",
    "        return np.sign(linear_output)\n",
    "\n",
    "# Trenowanie perceptronu\n",
    "perceptron = Perceptron(learning_rate=0.01, n_iters=1000)\n",
    "perceptron.fit(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZCIuqmHZXFnM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "ZCIuqmHZXFnM",
    "outputId": "ee2ad869-7f42-40d5-ab84-2d43f38c63b7"
   },
   "outputs": [],
   "source": [
    "# Wizualizacja\n",
    "plot_decision_boundary(X_test, y_test, perceptron)\n",
    "\n",
    "# Dok≈Çadno≈õƒá\n",
    "y_pred = perceptron.predict(X)\n",
    "accuracy = np.mean(y_pred == y)\n",
    "print(f\"Dok≈Çadno≈õƒá perceptronu: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WvLitAHyZbdG",
   "metadata": {
    "id": "WvLitAHyZbdG"
   },
   "outputs": [],
   "source": [
    "# Twoja implementacja z u≈ºyciem perceptronu z SKLEARNt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "N3XgXhWUmx2d",
   "metadata": {
    "id": "N3XgXhWUmx2d"
   },
   "source": [
    "## Klasyfikacja danych w kszta≈Çcie k√≥≈Ç za pomocƒÖ perceptronu\n",
    "\n",
    "W tym zadaniu wykorzystamy **perceptron** do klasyfikacji danych, kt√≥re uk≈ÇadajƒÖ siƒô w **koncentryczne ko≈Ça**. Celem jest sprawdzenie, jak klasyczny perceptron radzi sobie z danymi, kt√≥re nie sƒÖ liniowo separowalne.\n",
    "\n",
    "### Kroki:\n",
    "1. Wygeneruj dane w kszta≈Çcie k√≥≈Ç za pomocƒÖ `make_circles` z biblioteki `sklearn.datasets`.\n",
    "2. Wy≈õwietl dane na wykresie.\n",
    "3. Zaimplementuj perceptron lub u≈ºyj gotowego z `sklearn.linear_model`.\n",
    "4. Przeprowad≈∫ trening modelu na danych.\n",
    "5. Oce≈Ñ skuteczno≈õƒá modelu i zinterpretuj wyniki.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CZ9P_O5fm96Y",
   "metadata": {
    "id": "CZ9P_O5fm96Y"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "\n",
    "X,y=make_circles(random_state=42)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
