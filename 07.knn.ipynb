{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb9d6b1d",
   "metadata": {},
   "source": [
    "**Algorytm KNN**\n",
    "\n",
    "W najprostszej wersji algorytm KNN jest algorytmem klasyfikującym. Klasyfikacja obiektu polega na znalezieniu $K$ najbliższych sąsiadów względem wybranej przez nas metryki oraz wybraniu najliczniejszej klasy spośród tych sąsiadów.\n",
    "\n",
    "Algorytm KNN może też być stosowany w wersji regresyjnej. W tej wersji obiektowi przypisujemy wartość, która jest średnią wartości $K$ najbliższych sąsiadów."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40eed562",
   "metadata": {},
   "source": [
    "**Teoretyczne ograniczenia algorytmu KNN**\n",
    "\n",
    "$C_1, \\ldots, C_M$ - klasy, do których chcemy przypisywać obiekty.\n",
    "\n",
    "$X$ - rodzina obiektów, które chcemy klasyfikować.\n",
    "\n",
    "W teoretycznych rozważaniach przyjmuje się, że każdy obiekt ma zadany 'prawdziwy' rozkład prawdopodobieństw ($\\hat{P}(C_i | x)$ dla $x \\in X$) przynależności do klas.\n",
    "Zadaniem klasyfikatorów jest tak naprawdę aproksymacja tych rozkładów.\n",
    "\n",
    "Przez **błąd** klasyfikatora na obiekcie $x$ rozumiemy prawdopodobieństwo przypisania $x$ do niepoprawnej klasy\n",
    "$$\\texttt{Err}_x = \\sum_{i = 1}^{M} (C_i \\neq \\tilde{C}(x))\\hat{P}(C_i|x),$$\n",
    "gdzie $\\tilde{C}(x)$ to klasa, którą nasz klasyfikator przypisuje do $x$.\n",
    "\n",
    "Przez **współczynnik błędu** klasyfikatora rozumiemy oczekiwaną wartość błędu, gdy obiekt $x$ jest losowo wybrany z rodziny $X$. Niekoniecznie musi się to dziać z jednostajnym prawdopodobieństwem, ale na potrzeby naszych rozważań przyjmujemy takie założenie.\n",
    "$$\\texttt{Err} = E[\\texttt{Err}_x].$$\n",
    "\n",
    "Przez **Bayesowski współczynnik błędu** rozumiemy najniższy możliwy współczynnik błędu. Jest on równy współczynnikowi błędu 'idealnego' klasyfikatora, który zna prawdziwe rozkłady $\\hat{P}(C_i | x)$ i każdy element po prostu przypisuje do najbardziej prawdopodobnej klasy.\n",
    "\n",
    "W takiej sytuacji błąd na obiekcie $x$ upraszcza się do\n",
    "$$\\texttt{Err}_x = 1 - \\max_i \\hat{P}(C_i | x),$$\n",
    "\n",
    "a więc Bayesowski współczynnik błędu wyrażony jest przez\n",
    "$$B^* = E_x\\bigg[1 - \\max_i \\hat{P}(C_i | x)\\bigg].$$\n",
    "\n",
    "Po dokonaniu kilku zdroworozsądkowych założeń można udowodnić, że błąd klasyfikatora KNN jest co najwyżej dwa razy większy niż błąd Bayesowski.\n",
    "\n",
    "Dokładniejsze ograniczenie wynosi\n",
    "$$B_{kNN} \\leq B^*\\bigg(2 - \\frac{M B^*}{M - 1}\\bigg).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99639923",
   "metadata": {},
   "source": [
    "**Złożoność obliczeniowa**\n",
    "\n",
    "$T$ - rozmiar zbioru treningowego\n",
    "\n",
    "$S$ - rozmiar zbioru testowego\n",
    "\n",
    "$K$ - parametr KNN\n",
    "\n",
    "W naiwnej implementacji KNN porównujemy odległości obiektów $T \\cdot S \\cdot K$ razy. To dużo.\n",
    "\n",
    "Można tą ilość łatwo zmniejszyć wykorzystując *kopiec* (struktura danych) do $T \\cdot S \\cdot \\log K$.\n",
    "\n",
    "Czynnik $T \\cdot S$ można zmniejszyć wykorzystując zoptymalizowane struktury danych do przeszukiwania przestrzeni (np. $kd$-drzewa), jednak one zazwyczaj radzą sobie dobrze tylko w niewielkiej liczbie wymiarów.\n",
    "\n",
    "W praktyce, na naprawdę dużych zbiorach danych, stosuje się zazwyczaj algorytmy aproksymujące, które minimalnie zmniejszają zgodność klasyfikacji z oryginalną ideą algorytmu w zamian za znaczne zmniejszenie wymaganej liczby porównań."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbd54c5",
   "metadata": {},
   "source": [
    "**Wybór metryki**\n",
    "\n",
    "- Euklidesowa\n",
    "\n",
    "$$d(x, y) = \\sqrt{\\sum_{i = 1}^n (x_i - y_i)^2}$$\n",
    "\n",
    "- Manhattan\n",
    "\n",
    "$$d(x, y) = \\sum_{i = 1}^n |x_i - y_i|$$\n",
    "\n",
    "- Cosinusowa\n",
    "\n",
    "$$\\text{cossimilarity}(x, y) = \\frac{x \\cdot y}{ ||x|| \\cdot ||y|| } $$\n",
    "\n",
    "- Hamminga\n",
    "$$H(x, y) = \\sum_{i = 1}^n x_i \\neq y_i.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb480be",
   "metadata": {},
   "source": [
    "**Ważony KNN**\n",
    "\n",
    "Algorytm KNN można bardzo prosto uogólnić przypisując sąsiadom różne *wagi* na etapie wyboru najliczniejszej klasy. W najprostszej wersji algorytmu wszystkim sąsiadom przypisujemy stałą wagę $\\frac{1}{K}$.\n",
    "\n",
    "$d_i$ - dystans $i$-tego sąsiada od aktualnie rozpatrywanego obiektu \n",
    "\n",
    "W *ważonej* wersji KNN każdemu sąsiadowi przypisujemy wagę proporcjonalną do jego dystansu od rozpatrywanego obiektu\n",
    "$$\\frac{\\frac{1}{d_i}}{\\sum_{i = 1}^{K} \\frac{1}{d_i}}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13004c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from typing import Literal\n",
    "import requests\n",
    "import gzip\n",
    "import numpy as np\n",
    "import io\n",
    "import struct\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaad2ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _download_and_decompress(url):\n",
    "    print(f\"Downloading {url}...\")\n",
    "    response = requests.get(url)\n",
    "    with gzip.GzipFile(fileobj=io.BytesIO(response.content)) as f:\n",
    "        return f.read()\n",
    "\n",
    "def _read_images_from_bytes(data):\n",
    "    _, num_images, rows, cols = struct.unpack(\">IIII\", data[:16])\n",
    "    images = np.frombuffer(data[16:], dtype=np.uint8)\n",
    "    images = images.reshape(num_images, rows, cols)\n",
    "    return images\n",
    "\n",
    "def _read_labels_from_bytes(data):\n",
    "    labels = np.frombuffer(data[8:], dtype=np.uint8)\n",
    "    return labels\n",
    "\n",
    "def _parse_raw_data(url, func):\n",
    "    raw_data = _download_and_decompress(url)\n",
    "    return func(raw_data)\n",
    "\n",
    "def download_set(kind: Literal[\"train\", \"test\"]):\n",
    "    if kind == \"test\":\n",
    "        kind = \"t10k\" # Great naming.\n",
    "    url_images = f\"https://storage.googleapis.com/cvdf-datasets/mnist/{kind}-images-idx3-ubyte.gz\"\n",
    "    url_labels = f\"https://storage.googleapis.com/cvdf-datasets/mnist/{kind}-labels-idx1-ubyte.gz\"\n",
    "\n",
    "    return _parse_raw_data(url_images, _read_images_from_bytes), _parse_raw_data(url_labels, _read_labels_from_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1140573",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = download_set(\"train\")\n",
    "train_data, train_labels = train_data[:1000], train_labels[:1000]\n",
    "test_data, test_labels = download_set(\"test\")\n",
    "test_data, test_labels = test_data[:200], test_labels[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bc67c5",
   "metadata": {},
   "source": [
    "# **W rozwiązaniach zadań 1-7 nie wolno importować nowych bibliotek!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b764ba",
   "metadata": {},
   "source": [
    "**Zadanie 1.**\n",
    "\n",
    "Narysuj (na gridzie 2x5) po jednym przykładzie każdej z cyfr z danych treningowych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eec4ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d45f7ca",
   "metadata": {},
   "source": [
    "**Zadanie 2.**\n",
    "\n",
    "Zaimplementuj klasę `KNNClassifier`, która w konstruktorze przyjmuje treningowe obrazki, ich etykiety oraz parametr $K$.\n",
    "\n",
    "Klasa ta powinna mieć funkcję `classify`, która przyjmuje obrazek ze zbioru testowego, znajduje $K$ najbliższych sąsiadów i zwraca najbardziej popularną etykietę spośród tych sąsiadów. W przypadku remisów może zwracać dowolną najpopularniejszą etykietę.\n",
    "\n",
    "Możesz użyć dowolnej metryki spośród tych wymienionych w części teoretycznej.\n",
    "\n",
    "Pamiętaj, że obrazki są dwuwymiarowymi tablicami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd94fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39a0233",
   "metadata": {},
   "source": [
    "**Zadanie 3.**\n",
    "\n",
    "Stwórz instancję `KNNClassifier` z danymi treningowymi dla `K` równego 3. Dokonaj klasyfikacji zbioru testowego i oblicz accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2bfbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63195eef",
   "metadata": {},
   "source": [
    "**Zadanie 4.**\n",
    "\n",
    "Powtórz eksperyment dla `K` z zakresu 1 do 20. Narysuj wykres jak się zmienia accuracy w zależności od $K$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f87cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b2a654",
   "metadata": {},
   "source": [
    "**Zadanie 5.**\n",
    "\n",
    "Odczytaj z wykresu optymalne `K` względem accuracy. Wybierz 20 losowych obrazków, dla których Twój klasyfikator się pomylił. Narysuj je (jako grid 4x5) i podpisz poprawną etykietą oraz tą wskazaną przez klasyfikator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3cabe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e55defc",
   "metadata": {},
   "source": [
    "**Zadanie 6.**\n",
    "\n",
    "Zaimplementuj klasę `WeightedKNNClassifier`, która działa analogicznie do klasy `KNNClassifier`, ale implementuje *ważoną* wersję algorytmu KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a645d1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d8f630",
   "metadata": {},
   "source": [
    "**Zadanie 7.**\n",
    "\n",
    "Nanieś accuracy zwykłego oraz ważonego klasyfikatora KNN dla $K$ z przediału od 1 do 20 i oceń, który z tych klasyfikatorów sprawdził się lepiej dla tych danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35a3735",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c046a7b3",
   "metadata": {},
   "source": [
    "**Zadanie 8.**\n",
    "\n",
    "Wykorzystaj bibliotekę `scikit-learn` do znalezienia najlepszych hiperparametrów dla algorytmu KNN na zbiorze danych 'iris' wykorzystując podejście grid search.\n",
    "\n",
    "Sprawdź następujące zbiory hiperparametrów:\n",
    "- $K \\in [1, 20]$,\n",
    "- algorytm KNN zwykły albo ważony,\n",
    "- metryka euklidesowa lub Manhattan.\n",
    "\n",
    "Zbiór danych podziel na zbiór treningowy i testowy w proporcji 1:1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8e5379",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
