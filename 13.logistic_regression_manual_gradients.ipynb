{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc0e8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresja logistyczna "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:purple\"> Model probabilistyczny </span>\n",
    "Każdy przykład ze zbioru danych $x_i \\in X$ ma przypisaną etykietę $y_i \\in \\{1, \\ldots, K \\}$.\n",
    " <span style=\"color:purple\">Regresja logistyczna </span> jest jednym z klasycznych modeli, który bezpośrednio nadaje się zarówno do klasyfikacji binarnej (dwie klasy: $y_i \\in \\{0,1\\}$), jak i wieloklasowej. \n",
    "Ten model jest o tyle ważny, że stanowi podstawę modeli klasyfikacyjnych opartych o sieci neuronowe. \n",
    "\n",
    "Regresja logistyczna tworzy model probabilistyczny określający prawdopodobieństwo przynależności punktu do poszczególnych klas. \n",
    "W tym modelu chcemy dla każdego punktu wyznaczyć tak zwany rozkład a posteriori $p(1|x_i),\\ldots,p(K|x_i)$ określający przynależność punktu $x_i$ do każdej z $K$ klas. Jako finalną decyzję o klasyfikacji przyjmujemy tę najbardziej prawdopodobną, czyli:\n",
    "\n",
    "$$\n",
    "c(x) = \\arg \\max_{k \\in \\{1, \\dots, K\\}} p(k | x_i).\n",
    "$$\n",
    "\n",
    "Żeby zbudować taki model, musimy sparametryzować prawdopodobieństwa a posteriori, a następnie zbudować funkcję kosztu definiującą kryterium optymalizacyjne. W celu sparametryzowania $p(k|\\cdot)$, określmy moc przyporządkowania punktu $x$ do klasy $k$, wykorzystując model liniowy postaci:\n",
    "\n",
    "$$\n",
    "f_k(x) = w_k^T+b_k \\in \\mathbb{R}, \\quad \\text{dla} \\quad k \\in \\{1, \\ldots, K\\}.\n",
    "$$\n",
    "\n",
    "Mając $K$ takich modeli liniowych, możemy wskazać najbardziej prawdopodobną klasę poprzez wyznaczenie największej wartości $f_k(x)$ dla $k \\in \\{1, \\ldots, K\\}$.\n",
    "W celu transformacji tcyh funkcji do prawdopodobieństw wykorzystamy funkcję <span style=\"color:purple\"> softmax </span> postaci:\n",
    "\n",
    "$$\n",
    "p(k|x) = \\frac{\\exp(z_k)}{\\sum_{j=1}^{K}\\exp(z_j)} \\in (0,1),\n",
    "$$\n",
    "\n",
    "gdzie $z_k = f_k(x) = w_k^T + b_k.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:purple\"> Funkcja kosztu </span>\n",
    "\n",
    "Estymacja modelu regresji logistycznej polega na znalezieniu parametrów $w_k, b_k$ dla wszytskich klas. Standardowa metoda polega na maksymalizacji funkcji wiarygodności $\\prod_{i=1}^N p(y_i|x_i)$. Biorąc logarytm (z minusem) otrzymujemy problem minimalizacji:\n",
    "\n",
    "$$\n",
    "\\text{LR}_{w,b}(X,Y) = -\\log(X,Y) = - \\frac{1}{N} \\sum_{i=1}^N \\log p (y_i|x_i),\n",
    "$$\n",
    "\n",
    "gdzie $w= (w_1, \\ldots, w_K)$, $b = (b_1, \\ldots, b_K)$. W terminologii sieci neuronowych powyższą funkcję nazywa się często <span style=\"color:purple\">entropią krzyżową (z ang. cross-entropy) </span>. Entropia krzyżowa w połączeniu z funkcją softmax stanowi podstawową funkcję kosztu stosowaną w klasyfikacyjnych sieciach neuronowych. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W przypadku klasyfikacji binarnej (dwóch klas) musimy jedynie wyznaczyć jedynie $w_1,b_1$, ponieważ wartości  $w_2,b_2$ wyznaczamy korzystajac z definicji prawdopodobieństwa. W tej sytuacji prawdopodobienstwo a posteriori jest zadane za pomocą <span style=\"color:purple\">funkcji sigmoidalnej: </span>\n",
    "$$\n",
    "p(1|x) = \\frac{\\exp(w^Tx+b)}{1+\\exp(w^Tx+b)}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:purple\"> Minimalizacja gradientowa - gradient descent </span>\n",
    "Minimalizacja gradientowa <span style=\"color:purple\">(ang. Gradient Descent, DG)</span> to jedna z najczęściej używanych technik optymalizacji, która polega na iteracyjnym poszukiwaniu minimum funkcji kosztu (straty). Metoda ta jest fundamentalna w kontekście uczenia maszynowego i głębokiego uczenia, szczególnie w kontekście algorytmów takich jak regresja logistyczna czy sieci neuronowe. \n",
    "\n",
    "Celem minimalizacji gradientowej jest znalezienie takich wartości parametrów (wag), które minimalizują funkcję kosztu, czyli błędy predykcji modelu w stosunku do rzeczywistych danych. Działanie tej metody polega na obliczeniu gradientu funkcji kosztu względem wag modelu, a następnie „kroczymy” w kierunku przeciwnym do gradientu, aby zmniejszyć wartość funkcji kosztu. \n",
    "\n",
    "<span style=\"color:purple\">Kroki algorytmu minimalizacji gradientowej</span>.\n",
    "\n",
    "1. **Inicjalizacja wag**:  \n",
    "   Wagi (parametry modelu) są inicjowane losowo.\n",
    "\n",
    "2. **Obliczenie gradientu**:  \n",
    "   Dla bieżących wag, obliczamy gradient funkcji kosztu, czyli zestawienie wszystkich jej pochodnych cząstkowych. Gradient to wektor, który wskazuje kierunek, w którym funkcja kosztu rośnie najszybciej.\n",
    "\n",
    "3. **Aktualizacja wag**:  \n",
    "   Wagi są aktualizowane poprzez „krok” w kierunku przeciwnym do gradientu:\n",
    "   \n",
    "   $$\n",
    "   w_{\\text{new}} = w_{\\text{old}} - \\eta \\cdot \\nabla J(w)\n",
    "   $$\n",
    "   \n",
    "   gdzie:\n",
    "   - $ w_{\\text{new}} $ to nowe wagi,\n",
    "   - $ w_{\\text{old}} $ to obecne wagi,\n",
    "   - $ \\eta $ to współczynnik uczenia (learning rate),\n",
    "   - $\\nabla J(w)$ to gradient funkcji kosztu $ J $ względem wag $ w $.\n",
    "\n",
    "4. **Powtarzanie**:  \n",
    "   Proces ten jest powtarzany przez określoną liczbę iteracji lub do momentu, gdy zmiany wag staną się minimalne.\n",
    "\n",
    "\n",
    "### <span style=\"color:purple\">Uwaga</span>\n",
    "Wybór punktu startowego oraz współczynnika uczenia (learning rate) ma znaczenie dla działania algorytmu. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 1.\n",
    "Zaimplementuj funkcje sigmoidalną oraz softmax. Używając biblioteki matplotlib przedstaw wykresy tych funkcji dla przykładowych danych. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f879f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przykład danych\n",
    "x = np.linspace(-10, 10, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Zadanie 2 — Implementacja regresji logistycznej z ręcznym liczeniem gradientów\n",
    "\n",
    "Twoim zadaniem jest zaimplementowanie klasy `LogisticRegression` od podstaw, **bez używania automatycznego różniczkowania** (`autograd`, `.backward()`, `.grad` itd.). W tym celu trzeba napisać następujące funkcje:\n",
    "1. Funkcję kosztu modelu regresji logistycznej `loss(X, y)`, według następujących kroków:\n",
    "    * Policz model liniowy $z = w^Tx + b$\n",
    "    * Na wektorze $z$ zaimplementuj funkcję $\\hat{y} = \\sigma(z) = \\frac{1}{1 + \\exp(-z)}$.\n",
    "    * Policz entropię krzyżową pomiędzy predykcjami $\\hat{y}$ a etykietami $y$ zadaną przez:\n",
    "    $\\frac{1}{N} \\sum_i - (1 - y_i) \\ln (1 - \\hat{y}_i) - y_i \\ln \\hat{y}_i$\n",
    "2. Funkcję `predict_proba(X)` zwracającą dla każdego $x_i \\in X$ zadane przez nasz model prawdopodobieństwo $\\hat{p}(y = 1 \\mid x_i)$. \n",
    "3. Funkcję `predict(X)` zwracającą dla każdego $x_i \\in X$ przewidywaną etykietę (tzn. $0$ albo $1$). Zwracana etykieta powinna być typu `float`.\n",
    "4. Funkcję `fit`, w której należy:\n",
    "- policzyć predykcje `y_hat` przy użyciu funkcji sigmoidalnej,\n",
    "- obliczyć błąd `error = y_hat - y`,\n",
    "- obliczyć gradienty względem wag i biasu, **Nie używaj** `.backward()` ani `.grad` — wszystkie pochodne mają być wyznaczone **analitycznie**!\n",
    "- zaktualizować parametry modelu ręcznie przy użyciu algorytmu gradientowego.\n",
    "\n",
    "**UWAGA** Nie można korzystać z funkcji PyTorcha do liczenia entropii krzyżowej (np. `torch.nn.BCELoss`) ani sigmoidy (np.`torch.nn.functional.Sigmoid`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4440e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from collections import namedtuple\n",
    "\n",
    "if sys.version_info[0] < 3:\n",
    "    raise Exception(\"Must be using Python 3\")\n",
    "elif sys.version_info[1] < 7:\n",
    "    Dataset = namedtuple(\n",
    "        \"Dataset\",\n",
    "        [\"data\", \"target\", \"target_names\", \"filename\"],\n",
    "    )\n",
    "    Dataset.__new__.__defaults__ = (None,) * len(Dataset._fields)\n",
    "else:\n",
    "    Dataset = namedtuple(\n",
    "        \"Dataset\", [\"data\", \"target\", \"target_names\", \"filename\"], defaults=(None, None, None, None)\n",
    "    )\n",
    "\n",
    "def get_classification_dataset_1d() -> Dataset:\n",
    "    torch.manual_seed(8)\n",
    "    X = torch.cat(\n",
    "        [\n",
    "            torch.randn(10, 1) * 3 + 10,\n",
    "            torch.randn(10, 1) * 3 + 1,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    y = torch.cat([torch.zeros(10), torch.ones(10)])\n",
    "    return Dataset(X, y)\n",
    "\n",
    "\n",
    "def get_classification_dataset_2d() -> Dataset:\n",
    "    torch.manual_seed(4)\n",
    "    X = torch.cat(\n",
    "        [\n",
    "            torch.randn(50, 2) * 2 + torch.tensor([4.0, 2.0]),\n",
    "            torch.randn(50, 2) * 0.5 + torch.tensor([2.0, -4.0]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    y = torch.cat([torch.zeros(50), torch.ones(50)])\n",
    "    return Dataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36745573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przygotujmy datasety i funkcje pomocnicze\n",
    "dataset_1d = get_classification_dataset_1d()\n",
    "dataset_2d = get_classification_dataset_2d()\n",
    "\n",
    "\n",
    "def calculate_accuracy(\n",
    "    logistic_reg: \"LogisticRegression\", X: torch.Tensor, y: torch.Tensor\n",
    ") -> float:\n",
    "    preds = logistic_reg.predict(X)\n",
    "    correct_n = (preds == y).float().sum().item()\n",
    "    return float(correct_n / len(y))\n",
    "\n",
    "\n",
    "def plot_dataset_1d(logistic_reg: \"LogisticRegression\", dataset_1d: Dataset) -> None:\n",
    "    plt.scatter(dataset_1d.data[:10], [0.5] * 10, c=\"purple\", label=\"0\")\n",
    "    plt.scatter(dataset_1d.data[10:], [0.5] * 10, c=\"yellow\", label=\"1\")\n",
    "    linspace = torch.linspace(-7.5, 15, steps=100).view(-1, 1)\n",
    "    plt.plot(\n",
    "        linspace.numpy().ravel(),\n",
    "        logistic_reg.predict_proba(linspace).detach().numpy(),\n",
    "        label=\"p(y=1 | x)\",\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_dataset_2d(logistic_reg: \"LogisticRegression\", dataset_2d: Dataset) -> None:\n",
    "    plt.scatter(dataset_2d.data[:50, 0], dataset_2d.data[:50, 1], c=\"purple\", label=\"0\")\n",
    "    plt.scatter(dataset_2d.data[50:, 0], dataset_2d.data[50:, 1], c=\"yellow\", label=\"1\")\n",
    "\n",
    "    linspace_x = torch.linspace(-4, 7, steps=100)\n",
    "    linspace_y = (-logistic_reg.bias - logistic_reg.weight[0] * linspace_x) / logistic_reg.weight[1]\n",
    "\n",
    "    linspace_y = linspace_y.detach().numpy()\n",
    "    plt.plot(linspace_x.detach().numpy(), linspace_y, label=\"Granica decyzyjna\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99549247",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg = LogisticRegression(1)\n",
    "logistic_reg.fit(dataset_1d.data, dataset_1d.target, lr=1e-3, num_steps=int(2e4))\n",
    "acc = calculate_accuracy(logistic_reg, dataset_1d.data, dataset_1d.target)\n",
    "print(\"Accuracy\", acc)\n",
    "\n",
    "plot_dataset_1d(logistic_reg, dataset_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726565b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg = LogisticRegression(2)\n",
    "logistic_reg.fit(dataset_2d.data, dataset_2d.target, lr=1e-2, num_steps=int(2e4))\n",
    "acc = calculate_accuracy(logistic_reg, dataset_2d.data, dataset_2d.target)\n",
    "print(\"Accuracy\", acc)\n",
    "\n",
    "plot_dataset_2d(logistic_reg, dataset_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 3.\n",
    "\n",
    "Wykorzystując zaimplementowany algorytm minimalizacji gradientowej z poprzedniego zadania sprawdź, jak wybór punktu początkowego wpływa na działanie algorytmu.\n",
    "Twoim celem jest zminimalizowanie funkcji $f(x) = x^4 - 4 \\cdot x^3 + 3 \\cdot x^2 $ za pomocą algorytmu gradient descent.\n",
    "\n",
    "W tym celu należy wykonać następujące kroki:\n",
    "\n",
    "1. Napisać funkcję $ f(x) = x^4 - 4 \\cdot x^3 + 3 \\cdot x^2 $, która będzie reprezentować nasz obiekt do minimalizacji.\n",
    "2. Obliczyć pochodną tej funkcji.\n",
    "3. Zaimplemntować gradient descent.\n",
    "4. Spróbuj różnych wartości punktu początkowego i sprawdź, jak zmienia się zbieżność algorytmu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3f88e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcja, którą chcemy minimalizować za pomocą GD\n",
    "def f(x):\n",
    "    ...\n",
    "\n",
    "# Pochodna tej funkcji\n",
    "def df(x):\n",
    "    ...\n",
    "\n",
    "# Implementacja algorytmu minimalizacji gradientowej\n",
    "def gradient_descent(starting_point, learning_rate, iterations):\n",
    "    ...\n",
    "    \n",
    "x_vals = np.linspace(-1, 3, 400)\n",
    "y_vals = f(x_vals)\n",
    "\n",
    "# Parametry minimalizacji gradientowej\n",
    "learning_rate = 0.01\n",
    "iterations = 30\n",
    "\n",
    "# Punkty startowe dla dwóch różnych trajektorii\n",
    "starting_point_1 = -1  \n",
    "starting_point_2 = 3  \n",
    "\n",
    "# Obliczanie trajektorii dla obu punktów startowych\n",
    "trajectory_1 = gradient_descent(starting_point_1, learning_rate, iterations)\n",
    "trajectory_2 = gradient_descent(starting_point_2, learning_rate, iterations)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "\n",
    "axs[0].plot(x_vals, y_vals, label=\"Funkcja f(x)\", color=\"blue\")\n",
    "axs[0].plot(trajectory_1, f(np.array(trajectory_1)), label=f\"Trajektoria (start {starting_point_1})\", color=\"red\", marker='o')\n",
    "axs[0].set_title(\"Minimum lokalne\")\n",
    "axs[0].set_xlabel(\"x\")\n",
    "axs[0].set_ylabel(\"f(x)\")\n",
    "axs[0].grid(True)\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(x_vals, y_vals, label=\"Funkcja f(x)\", color=\"blue\")\n",
    "axs[1].plot(trajectory_2, f(np.array(trajectory_2)), label=f\"Trajektoria (start {starting_point_2})\", color=\"green\", marker='o')\n",
    "axs[1].set_title(\"Minimum globalne\")\n",
    "axs[1].set_xlabel(\"x\")\n",
    "axs[1].set_ylabel(\"f(x)\")\n",
    "axs[1].grid(True)\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 4 \n",
    "\n",
    "Rozważ funkcję:\n",
    "\n",
    "$$\n",
    "f(x_1, x_2) = \\log(1 + x_1^2 + x_2^2) + \\exp(0.1 x_1 x_2)\n",
    "$$\n",
    "\n",
    "Twoim celem jest zminimalizowanie tej funkcji przy użyciu **ręcznie zaimplementowanego gradient descent**, **bez automatycznego różniczkowania**.\n",
    "Wykonaj następujące kroki:\n",
    "\n",
    "1. Zaimplementuj funkcję `f(x)`, przyjmującą `x = [x1, x2]`.\n",
    "2. Ręcznie oblicz gradient tej funkcji\n",
    "3. Zaimplementuj algorytm gradient descent.\n",
    "4. Przetestuj działanie algorytmu dla różnych punktów startowych.\n",
    "5. Przedstaw wizualizację ścieżek zbieżności algorytmu."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
